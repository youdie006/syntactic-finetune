#!/usr/bin/env python3
"""
ë¬¸ë²• ì£¼ì„ í…ìŠ¤íŠ¸ íŒŒì¼ì„ CSVë¡œ ë³€í™˜í•˜ëŠ” ë©”ì¸ ìƒì„±ê¸°
"""

import pandas as pd
import json
import re
import os
import argparse
from typing import List, Dict, Any
import openpyxl


class SyntacticCSVGenerator:
    """ë¬¸ë²• ì£¼ì„ì´ ë‹¬ë¦° í…ìŠ¤íŠ¸ë¥¼ CSVë¡œ ë³€í™˜"""
    
    def __init__(self):
        self.patterns = self._load_patterns()
    
    def _load_patterns(self) -> Dict:
        """ì €ì¥ëœ íŒ¨í„´ ë¡œë“œ (ìˆìœ¼ë©´)"""
        if os.path.exists('original_patterns.json'):
            with open('original_patterns.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _generate_id(self, index: int) -> str:
        """sentence_id ìƒì„± (UUID í˜•ì‹)"""
        import uuid
        return str(uuid.uuid4())
    
    def process_file(self, input_path: str) -> List[Dict]:
        """ì…ë ¥ íŒŒì¼ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ë˜ëŠ” ì—‘ì…€)"""
        if input_path.endswith('.xlsx') or input_path.endswith('.xls'):
            return self._process_excel(input_path)
        else:
            return self._process_text(input_path)
    
    def _process_excel(self, excel_path: str) -> List[Dict]:
        """ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬"""
        df = pd.read_excel(excel_path)
        data = []
        sentence_count = 0
        
        for idx, row in df.iterrows():
            # ë¹ˆ í–‰ ê±´ë„ˆë›°ê¸°
            if pd.isna(row.iloc[0]) or str(row.iloc[0]).strip() == '':
                continue
            
            sentence = str(row.iloc[0]).strip()  # ì˜ì–´ ë¬¸ì¥
            translation = str(row.iloc[1]).strip() if not pd.isna(row.iloc[1]) else ""  # í•œêµ­ì–´ ë²ˆì—­
            
            # ë¬¸ë²• íƒœê·¸ ìˆ˜ì§‘ (ë¬¸ë²• íƒœê·¸ 1~6 ì»¬ëŸ¼)
            tags = []
            for i in range(2, min(len(row), 8)):  # ìµœëŒ€ 6ê°œ íƒœê·¸
                if not pd.isna(row.iloc[i]) and str(row.iloc[i]).strip():
                    tag = str(row.iloc[i]).strip()
                    if tag.startswith('[') and tag.endswith(']'):
                        tags.append(tag)
            
            # ë°ì´í„° ìƒì„±
            if sentence in self.patterns:
                # íŒ¨í„´ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                pattern = self.patterns[sentence]
                data.append({
                    'sentence_id': self._generate_id(sentence_count),
                    'sentence': sentence,
                    'translation': pattern['translation'],
                    'slash_translate': json.dumps(pattern['slash_translate'], ensure_ascii=False),
                    'tag_info': json.dumps(pattern['tag_info'], ensure_ascii=False),
                    'syntax_info': '[]'
                })
            else:
                # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒì„±
                data.append(self._create_default_entry(
                    sentence, translation, tags, sentence_count
                ))
            
            sentence_count += 1
        
        return data
    
    def _process_text(self, text_path: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬"""
        data = []
        
        with open(text_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        sentence_count = 0
        i = 0
        
        while i < len(lines):
            line = lines[i].strip()
            # ë¼ì¸ ë²ˆí˜¸ ì œê±°
            line = re.sub(r'^\d+â†’', '', line).strip()
            
            # ì˜ì–´ ë¬¸ì¥ ì°¾ê¸°
            if line and line[0].isupper() and not line.startswith('['):
                sentence = line
                translation = ""
                tags = []
                
                # ë‹¤ìŒ ë¼ì¸ì—ì„œ ë²ˆì—­ ì°¾ê¸°
                j = i + 1
                if j < len(lines):
                    next_line = lines[j].strip()
                    next_line = re.sub(r'^\d+â†’', '', next_line).strip()
                    if next_line and not next_line.startswith('[') and not next_line[0].isupper():
                        translation = next_line
                        j += 1
                
                # íƒœê·¸ ìˆ˜ì§‘
                while j < len(lines):
                    tag_line = lines[j].strip()
                    tag_line = re.sub(r'^\d+â†’', '', tag_line).strip()
                    
                    if tag_line.startswith('['):
                        tags.append(tag_line)
                    elif tag_line == "" or (tag_line and tag_line[0].isupper()):
                        break
                    j += 1
                
                # ë°ì´í„° ìƒì„±
                if sentence in self.patterns:
                    # íŒ¨í„´ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                    pattern = self.patterns[sentence]
                    data.append({
                        'sentence_id': self._generate_id(sentence_count),
                        'sentence': sentence,
                        'translation': pattern['translation'],
                        'slash_translate': json.dumps(pattern['slash_translate'], ensure_ascii=False),
                        'tag_info': json.dumps(pattern['tag_info'], ensure_ascii=False),
                        'syntax_info': '[]'
                    })
                else:
                    # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒì„±
                    data.append(self._create_default_entry(
                        sentence, translation, tags, sentence_count
                    ))
                
                sentence_count += 1
            
            i += 1
        
        return data
    
    def _create_default_entry(self, sentence: str, translation: str, 
                             tags: List[str], index: int) -> Dict:
        """ê¸°ë³¸ ë°ì´í„° í•­ëª© ìƒì„±"""
        # ë‹¨ì–´ ë¶„ë¦¬
        words = sentence.replace(',', ' ,').replace('.', ' .').replace(':', ' :').split()
        
        # ê¸°ë³¸ slash_translate
        slash_translate = [{
            'start_idx': 0,
            'end_idx': len(words) - 1,
            'sentence': sentence,
            'translation': translation,
            'words': words
        }]
        
        # tag_info ìƒì„±
        tag_info = []
        for tag in tags:
            match = re.match(r'\[(.+) -> (.+)\]', tag)
            if match:
                tag_text = match.group(1)
                tag_type = match.group(2)
                
                # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                category = self._classify_category(tag_type)
                
                tag_info.append({
                    'tag': tag[1:-1],
                    'category': category,
                    'words': []
                })
        
        return {
            'sentence_id': self._generate_id(index),
            'sentence': sentence,
            'translation': translation,
            'slash_translate': json.dumps(slash_translate, ensure_ascii=False),
            'tag_info': json.dumps(tag_info, ensure_ascii=False),
            'syntax_info': '[]'
        }
    
    def _classify_category(self, tag_type: str) -> str:
        """íƒœê·¸ íƒ€ì…ì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        if 'ì ‘ì†ì‚¬' in tag_type:
            return 'ì ‘ì†ì‚¬'
        elif 'ë™ì‚¬' in tag_type or 'ì‹œì œ' in tag_type:
            return 'ë™ì‚¬_ì‹œì œ'
        elif 'ê´€ê³„' in tag_type:
            return 'ê´€ê³„ì‚¬'
        elif 'ì „ì¹˜ì‚¬' in tag_type:
            return 'ì „ì¹˜ì‚¬'
        elif 'ë™ëª…ì‚¬' in tag_type or 'ë¶„ì‚¬' in tag_type or 'toë¶€ì •ì‚¬' in tag_type:
            return 'ì¤€ë™ì‚¬'
        else:
            return 'êµ¬ë¬¸'
    
    def generate_csv(self, input_path: str, output_path: str) -> pd.DataFrame:
        """CSV ìƒì„±"""
        file_type = 'ğŸ““ ì—‘ì…€' if input_path.endswith(('.xlsx', '.xls')) else 'ğŸ“„ í…ìŠ¤íŠ¸'
        print(f"\n{file_type} ì…ë ¥ íŒŒì¼: {input_path}")
        print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼: {output_path}")
        print(f"ğŸ†” ID í˜•ì‹: UUID")
        
        # ë°ì´í„° ì²˜ë¦¬
        data = self.process_file(input_path)
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(data)
        
        # CSV ì €ì¥
        columns = ['sentence_id', 'sentence', 'translation', 
                  'slash_translate', 'tag_info', 'syntax_info']
        df[columns].to_csv(output_path, index=False, encoding='utf-8')
        
        print(f"\nâœ… CSV ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ {len(df)}ê°œì˜ ë¬¸ì¥ ì²˜ë¦¬")
        
        return df


def main():
    parser = argparse.ArgumentParser(
        description='ë¬¸ë²• ì£¼ì„ í…ìŠ¤íŠ¸ë¥¼ CSVë¡œ ë³€í™˜'
    )
    parser.add_argument(
        'input', 
        help='ì…ë ¥ íŒŒì¼ ê²½ë¡œ (.txt ë˜ëŠ” .xlsx)'
    )
    parser.add_argument(
        '-o', '--output',
        default='syntactic_analysis.csv',
        help='ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: syntactic_analysis.csv)'
    )
    
    args = parser.parse_args()
    
    # CSV ìƒì„±
    generator = SyntacticCSVGenerator()
    df = generator.generate_csv(args.input, args.output)
    
    # ìƒ˜í”Œ ì¶œë ¥
    print("\nğŸ“‹ ìƒì„±ëœ CSV ìƒ˜í”Œ:")
    print("-" * 60)
    for idx in range(min(3, len(df))):
        print(f"\n[ë¬¸ì¥ {idx+1}]")
        print(f"ID: {df.iloc[idx]['sentence_id']}")
        print(f"ë¬¸ì¥: {df.iloc[idx]['sentence'][:50]}...")
        slash_data = json.loads(df.iloc[idx]['slash_translate'])
        print(f"ì²­í¬ ìˆ˜: {len(slash_data)}")


if __name__ == "__main__":
    main()