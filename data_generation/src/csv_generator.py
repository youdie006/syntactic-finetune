#!/usr/bin/env python3
"""
CSV Generator - ì›ì‹œ í…ìŠ¤íŠ¸ì—ì„œ êµ¬ë¬¸ ë¶„ì„ CSV ìƒì„±
"""

import json
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from language_analyzer import LanguageAnalyzer
from data_formatter import DataFormatter
from improved_formatter import ImprovedDataFormatter


@dataclass
class SentenceData:
    """ë‹¨ì¼ ë¬¸ì¥ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    sentence_id: str
    sentence: str
    translation: Optional[str] = None
    slash_translate: Optional[Dict] = None
    tag_info: Optional[List[Dict]] = None
    syntax_info: Optional[List] = None


class CSVGenerator:
    """
    ì›ì‹œ í…ìŠ¤íŠ¸ì—ì„œ êµ¬ë¬¸ ë¶„ì„ CSVë¥¼ ìƒì„±í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤
    """
    
    def __init__(self, use_translation: bool = False, use_improved_formatter: bool = True):
        """
        Args:
            use_translation: ë²ˆì—­ ì„œë¹„ìŠ¤ ì‚¬ìš© ì—¬ë¶€
            use_improved_formatter: ê°œì„ ëœ í¬ë§·í„° ì‚¬ìš© ì—¬ë¶€
        """
        self.analyzer = LanguageAnalyzer()
        if use_improved_formatter:
            self.formatter = ImprovedDataFormatter()
        else:
            self.formatter = DataFormatter()
        self.use_translation = use_translation
        
    def generate_sentence_id(self) -> str:
        """ê³ ìœ í•œ ë¬¸ì¥ ID ìƒì„±"""
        timestamp = int(datetime.now().timestamp() * 1000000)
        return str(timestamp)
    
    def clean_sentence_for_csv(self, sentence: str) -> str:
        """CSV ì €ì¥ì„ ìœ„í•´ ë¬¸ì¥ì—ì„œ ê°œí–‰ ë¬¸ì ì œê±°"""
        return sentence.replace('\n', ' ').replace('\r', ' ').strip()
    
    def analyze_single_sentence(self, sentence: str, translation: Optional[str] = None) -> SentenceData:
        """
        ë‹¨ì¼ ë¬¸ì¥ì„ ë¶„ì„í•˜ì—¬ SentenceData ê°ì²´ ë°˜í™˜
        
        Args:
            sentence: ë¶„ì„í•  ì˜ì–´ ë¬¸ì¥ (ì£¼ì„ í¬í•¨ ê°€ëŠ¥)
            translation: í•œêµ­ì–´ ë²ˆì—­ (ì„ íƒì‚¬í•­)
            
        Returns:
            SentenceData: ë¶„ì„ ê²°ê³¼
        """
        # ê¸°ë³¸ ì •ë³´
        sentence_id = self.generate_sentence_id()
        
        # ì–¸ì–´ ë¶„ì„ ìˆ˜í–‰
        analysis_result = self.analyzer.analyze(sentence)
        
        # ì‹¤ì œ ì˜ì–´ ë¬¸ì¥ ì¶”ì¶œ (ì£¼ì„ ì œê±°)
        clean_sentence = analysis_result.sentence
        
        # ë°ì´í„° í¬ë§·íŒ…
        slash_translate = self.formatter.format_slash_translate(analysis_result)
        tag_info = self.formatter.format_tag_info(analysis_result)
        
        # ë²ˆì—­ ì²˜ë¦¬ (ë¶„ì„ ê²°ê³¼ì—ì„œ ë²ˆì—­ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)
        if translation is None:
            translation = analysis_result.translation or ""
        
        return SentenceData(
            sentence_id=sentence_id,
            sentence=clean_sentence,  # ê¹¨ë—í•œ ì˜ì–´ ë¬¸ì¥ë§Œ ì €ì¥
            translation=translation,
            slash_translate=slash_translate,
            tag_info=tag_info,
            syntax_info=[]  # ê¸°ì¡´ CSVì—ì„œ ë¹ˆ ë°°ì—´ë¡œ ì‚¬ìš©ë¨
        )
    
    def process_sentences(self, sentences: List[str], translations: Optional[List[str]] = None) -> List[SentenceData]:
        """
        ì—¬ëŸ¬ ë¬¸ì¥ì„ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            sentences: ë¶„ì„í•  ì˜ì–´ ë¬¸ì¥ë“¤
            translations: í•œêµ­ì–´ ë²ˆì—­ë“¤ (ì„ íƒì‚¬í•­)
            
        Returns:
            List[SentenceData]: ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, sentence in enumerate(sentences):
            translation = translations[i] if translations and i < len(translations) else None
            
            try:
                result = self.analyze_single_sentence(sentence, translation)
                results.append(result)
                print(f"Processed {i+1}/{len(sentences)}: {sentence[:50]}...")
                
            except Exception as e:
                print(f"Error processing sentence {i+1}: {e}")
                continue
                
        return results
    
    def _format_json_with_single_quotes(self, data: Any) -> str:
        """JSONì„ single quote í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
        json_str = json.dumps(data, ensure_ascii=False)
        # Double quotesë¥¼ single quotesë¡œ ë³€ê²½
        return json_str.replace('"', "'")
    
    def save_to_csv(self, sentence_data: List[SentenceData], output_path: str) -> None:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            sentence_data: ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        # DataFrame ìƒì„±
        rows = []
        for data in sentence_data:
            row = {
                'sentence_id': data.sentence_id,
                'sentence': self.clean_sentence_for_csv(data.sentence),  # ê°œí–‰ ë¬¸ì ì œê±°
                'translation': data.translation or "",
                'slash_translate': self._format_json_with_single_quotes(data.slash_translate),
                'tag_info': self._format_json_with_single_quotes(data.tag_info),
                'syntax_info': self._format_json_with_single_quotes(data.syntax_info)
            }
            rows.append(row)
        
        df = pd.DataFrame(rows)
        
        # CSV ì €ì¥ (ê¸°ì¡´ í˜•ì‹ê³¼ ë™ì¼í•˜ê²Œ)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"âœ… CSV saved to: {output_path}")
        print(f"Total sentences: {len(sentence_data)}")
    
    def parse_annotated_file(self, input_path: str) -> List[tuple]:
        """
        ì£¼ì„ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì˜ì–´ ë¬¸ì¥ê³¼ ì£¼ì„ ë¶„ë¦¬
        
        Returns:
            List[tuple]: (ì˜ì–´ ë¬¸ì¥, ì£¼ì„ ë¸”ë¡) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        # ë¹ˆ ì¤„ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¸”ë¡ ë¶„ë¦¬
        sentence_blocks = content.split('\n\n')
        
        processed_sentences = []
        for block in sentence_blocks:
            if not block.strip():
                continue
                
            # LanguageAnalyzerë¥¼ ì‚¬ìš©í•´ ì˜ì–´ ë¬¸ì¥, ì£¼ì„, ë²ˆì—­ ë¶„ë¦¬
            english_sentence, annotations, translation = self.analyzer.parse_annotated_text(block)
            processed_sentences.append((english_sentence, block))
            
        return processed_sentences
    
    def generate_from_text_file(self, input_path: str, output_path: str, 
                               translation_path: Optional[str] = None) -> None:
        """
        í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ CSV ìƒì„±
        
        Args:
            input_path: ì…ë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ
            translation_path: ë²ˆì—­ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        # ì…ë ¥ íŒŒì¼ ì½ê¸° (ì£¼ì„ í¬í•¨ í˜•ì‹ ì§€ì›)
        if self._is_annotated_file(input_path):
            sentence_data = self.parse_annotated_file(input_path)
            sentences = [data[1] for data in sentence_data]  # ì „ì²´ ì£¼ì„ ë¸”ë¡ ì‚¬ìš©
        else:
            with open(input_path, 'r', encoding='utf-8') as f:
                sentences = [line.strip() for line in f if line.strip()]
        
        # ë²ˆì—­ íŒŒì¼ ì½ê¸° (ìˆëŠ” ê²½ìš°)
        translations = None
        if translation_path:
            with open(translation_path, 'r', encoding='utf-8') as f:
                translations = [line.strip() for line in f if line.strip()]
        
        # ë¶„ì„ ë° ì €ì¥
        print(f"ğŸš€ Processing {len(sentences)} sentences...")
        results = self.process_sentences(sentences, translations)
        self.save_to_csv(results, output_path)
    
    def _is_annotated_file(self, file_path: str) -> bool:
        """
        íŒŒì¼ì´ ì£¼ì„ í¬í•¨ í˜•ì‹ì¸ì§€ í™•ì¸
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(1000)  # ì²˜ìŒ 1000ìë§Œ í™•ì¸
                return '\n[' in content and ' -> ' in content
        except:
            return False


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì‹¤í–‰
    generator = CSVGenerator()
    
    test_sentences = [
        "This is a simple test sentence.",
        "The quick brown fox jumps over the lazy dog.",
        "Natural language processing is fascinating."
    ]
    
    results = generator.process_sentences(test_sentences)
    generator.save_to_csv(results, "data_generation/output/test_output.csv")